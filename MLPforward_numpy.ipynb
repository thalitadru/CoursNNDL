{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-29T22:47:13.982074Z",
     "start_time": "2018-09-29T22:47:13.672095Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "def plot_y(y_pred, y_true):\n",
    "    y_pred = y_pred.reshape(-1)\n",
    "    y_true = y_true.reshape(-1)\n",
    "    order = np.argsort(y_pred)\n",
    "    plt.plot(y_true[order], 'o ', label=u'réel ')\n",
    "    plt.plot(y_pred[order], 'P ', label=u'prédiction ')\n",
    "    plt.legend()\n",
    "    plt.xlabel(u'échantillons')\n",
    "    plt.ylabel('valeur de y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron multicouches (Multilayer perceptron - MLP)\n",
    "\n",
    "Dans cet exercice nous allons réaliser un perceptron à une couche caché. On l'utilisera pour predire la progression du diabetes à partir de 10 types de caracteristiques de pacients. D'abord, on écrira le code qui decrit le modéle qui fait les predictions: le pas en avant ou \"forward pass\". Dans un prochain moment on écrira le code pour optimizer ce modèle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les données : Predire la progression du diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "data = load_diabetes()\n",
    "\n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici un aperçu des données qu'on utilisera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X, y = data.data, data.target\n",
    "pd.DataFrame(X[:10,:], columns=data.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour vérifier que notre modèle generalise bien pour des cas inconnus, il est important de separer une portion des données qui ne sera pas utilisé dans l'entraînement, qu'on appelle ensemble de test ou validation. On va aussi faire un pretraitement pour que les valeurs pour chaque \"feature\" restent dans l'intervale [0,1]. Ceci est fait ci-desous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# from sklearn.feature_selection import f_regression\n",
    "# feats = np.argsort(f_regression(X_train, y_train))[1][0:2]\n",
    "# X_train, X_test = X_train[:,feats], X_test[:,feats],\n",
    "\n",
    "y_train, y_test = y_train.reshape([-1,1]), y_test.reshape([-1,1])\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice \n",
    "Regardez la dimension de X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# votre code ici !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP en numpy\n",
    "\n",
    "On comencera par écrire les variables du modèle et ses equations en numpy.\n",
    "Tout d'abord, pour nous faciliter la vie, on va creer des variables avec le nombre d'échantillons, de features et de sorties de notre réseau, une fois que ces tailles seront important pour définir nos matrices de paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "M = X_train.shape[0]  # nombre d'échantillons\n",
    "D = X_train.shape[1]  # nombre de features\n",
    "S = y_train.shape[1]  # nombre de sorties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice : imprimez et regardez les valeurs de M, D et S  ici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# votre code ici !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création des paramètres du modèle\n",
    "\n",
    "Dans nos équations on a quelques parametres mutables qui permentent au modèle d'apprendre et s'ajuster aux données. Ce sont:\n",
    "- les poids de la couche caché W\n",
    "- les biais de la couche caché b\n",
    "- les poids de la couche de sortie O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice: Regardez dans le cours les tailles de ces matrices et completez le code ci desous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameters(D, S, N=10):\n",
    "    # N le nombre de neurones de la couche caché\n",
    "    rng = np.random.RandomState(0)\n",
    "    \n",
    "    # changez les tailles des matrices ici pour leurs valeurs correctes\n",
    "    tailleW = (0,0)\n",
    "    tailleb = (0,0)\n",
    "    tailleO = (0,0)\n",
    "  \n",
    "    W = rng.rand(*tailleW)\n",
    "    b = np.zeros(tailleb)\n",
    "    \n",
    "    O = rng.rand(*tailleO)\n",
    "    \n",
    "    return W, b, O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul de la prediction du modèle\n",
    "\n",
    "Ici on ira décrire les equations du perceptron multicouches qui donnent les valeurs de sortie Y. Pour rappel, les voici en forme matricielle:\n",
    "\n",
    "$$H = XW+b^T$$\n",
    "$$A = \\sigma(H)$$\n",
    "$$Y = AO$$\n",
    "\n",
    "On utilisera comme fonction d'activation $\\sigma=\\tanh$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice : écrivez les equations pour le calcul de H et A ci-dessous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(X, W, b, O):\n",
    "    M, D = X.shape  # nombre d'échantillons, nombre de features\n",
    "    N = W.shape[1]  # N le nombre de neurones de la couche caché\n",
    "    \n",
    "    # écrivez le calcul de H\n",
    "    H = np.zeros(1) # changez ici pour avoir la bonne equation de H\n",
    "    A = np.tanh(H)  \n",
    "\n",
    "    # écrivez le calul de Y\n",
    "    Y = np.zeros(1) # changez ici pour avoir la bonne equation de Y\n",
    "    \n",
    "    # Ici quelques verifications sur la taille des matrices pour vous aider\n",
    "    try:\n",
    "        assert(H.shape == (M,N))\n",
    "    except AssertionError:\n",
    "        print(\"Taille de H semble erronée:\",H.shape, \", ça devrait être\", (M,N))    \n",
    "\n",
    "    try:\n",
    "        assert(Y.shape == (M,S))\n",
    "    except AssertionError:\n",
    "        print(\"Taille de Y semble erronée:\",Y.shape, \", ça devrait être\", (M,S))\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La fonction de coût\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cout(Y_pred, Y_true):\n",
    "    M = Y_true.shape[0]\n",
    "    # completez le code avec l'expression pour la fonction de cout J\n",
    "    J = 0 # changez ici pour avoir la bonne equation de J\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tout ensemble: creation du MLP\n",
    "Maintenant on utlisera toutes les fonctions qu'on à écrites cidessus.\n",
    "\n",
    "Tout d'abord on utilisera la fonction `parameters` pour creéer nos paramètres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, b, O = parameters(D, S, N=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite on utilisera ces parametres et la fonction `MLP` pour obtenir les predictions de notre réseau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = MLP(X_train, W, b, O)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalment, on peut calculer la valeur de la fonction de cout pour les predictions qui ont été faites:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = cout(Y_pred, y_train)\n",
    "J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Vouz pourez voire ci dessus les predictions courantes du réseau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_y(Y_pred, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# À venir: la retro-propagation des gradients !\n",
    "\n",
    "Au prochain notebook on écrira la boucle d'optimization pour que notre réseau aprenne à predire la progression du diabetes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrigés\n",
    "\n",
    "Les `...` indiquent des portions de code que je n'ai pas répeté ici et que ne sont pas a changer.\n",
    "\n",
    "### Tailles des matrices\n",
    "``` python\n",
    "def parameters(D, S, N=10):\n",
    "    ...\n",
    "    # changez les tailles des matrices ici pour leurs valeurs correctes\n",
    "    tailleW = (D,N)\n",
    "    tailleb = (N,1)\n",
    "    tailleO = (N,S)\n",
    "    ...\n",
    "```\n",
    "\n",
    "### MLP numpy\n",
    "``` python\n",
    "def MLP(X, W, b, O):\n",
    "    M, D = X.shape  # nombre d'échantillons, nombre de features\n",
    "    N = W.shape[1]  # N le nombre de neurones de la couche caché\n",
    "    \n",
    "    # écrivez le calcul de H\n",
    "    H = np.dot(X,W) + b.T # changez ici pour avoir la bonne equation de H\n",
    "    A = np.tanh(H)  \n",
    "\n",
    "    # écrivez le calul de Y\n",
    "    Y = np.dot(A,O) # changez ici pour avoir la bonne equation de Y\n",
    "    ...\n",
    "```    \n",
    "#### Fonction de coût\n",
    "``` python\n",
    "def cout(Y_pred, Y_true):\n",
    "    M = Y_true.shape[0]\n",
    "    # completez le code avec l'expression pour la fonction de cout J\n",
    "    J = (1/2)*np.mean((Y_pred - Y_true)**2) # changez ici pour avoir la bonne equation de J\n",
    "    return J\n",
    "\n",
    "```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "name": "python3810jvsc74a57bd07dba6e18e6acdf8fcfcaa1bbab0f558cda8ecf0f594e6f632ac4fb60f19865cf",
   "display_name": "Python 3.8.10 64-bit ('CoursNNDL': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "rise": {
   "theme": "simple",
   "transition": "none"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "327.009px",
    "width": "355.999px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "164.997px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.085px",
    "left": "1310.04px",
    "right": "20px",
    "top": "161.992px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "metadata": {
   "interpreter": {
    "hash": "7dba6e18e6acdf8fcfcaa1bbab0f558cda8ecf0f594e6f632ac4fb60f19865cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
